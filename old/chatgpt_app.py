"""æœ¬æ–‡ä»¶ä¸ºæ•´ä¸ªé¡¹ç›®çš„ä¸»æ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨gradioæ­å»ºç•Œé¢"""
# https://github.com/GaiZhenbiao/ChuanhuChatGPT
from openai import RateLimitError,APIConnectionError
import subprocess
import traceback
from fastapi import FastAPI, Depends, Request
import gradio as gr
from modules import utils
from modules.NLG import ChatGPT,NLGEnum
import uvicorn
import os
from langchain.document_loaders import (UnstructuredPowerPointLoader, UnstructuredWordDocumentLoader, PyPDFLoader, UnstructuredFileLoader, CSVLoader, MWDumpLoader)
from langchain.text_splitter import (RecursiveCharacterTextSplitter, CharacterTextSplitter)
from modules.utils import  get_history_names, get_first_history_name
app = FastAPI()
Configs = utils.Configs
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chatgpt_service = ChatGPT(Configs["Chatgpt"])


with gr.Blocks(theme=gr.themes.Soft(), title="Chatbot Client", css="./assets/css/GenshinStyle.css",
               js="./assets/js/GenshinStyle.js") as chat_demo:
    with gr.Row(elem_id="baseContainer"):
        with gr.Group():
            with gr.Row(elem_id="history-body"):
                with gr.Column(scale=6, elem_id="history-select-wrap"):
                    historySelectList = gr.Radio(
                        label="ä»åˆ—è¡¨ä¸­åŠ è½½å¯¹è¯",
                        choices=get_history_names(user_name='system'),
                        value=get_first_history_name(user_name='system'),
                        # multiselect=False,
                        container=False,
                        elem_id="history-select-dropdown"
                    )
                with gr.Row(visible=False):
                    with gr.Column(min_width=42, scale=1):
                        historyDeleteBtn = gr.Button(
                            "ğŸ—‘ï¸", elem_id="gr-history-delete-btn")
                    with gr.Column(min_width=42, scale=1):
                        historyDownloadBtn = gr.Button(
                            "â¬", elem_id="gr-history-download-btn")
                    with gr.Column(min_width=42, scale=1):
                        historyMarkdownDownloadBtn = gr.Button(
                            "â¤µï¸", elem_id="gr-history-mardown-download-btn")
        with gr.Column(min_width=280, elem_id="sideBar"):
            # NLGENUM æ˜¯å¤§è¯­è¨€æ¨¡å‹åˆ—è¡¨chatgpt  llamaç­‰ç­‰ [i.name for i in NLGEnum]
            chatgpt_switch = gr.Dropdown(
                [
                    'gpt-3.5-turbo',
                    'gpt-3.5-turbo-16k',
                    'gpt-4',
                    'gpt-4-0125-preview',
                    'gpt-4-turbo-preview',
                    'gpt-4-1106-preview',
                    'gpt-4-vision-preview',
                    'gpt-4-1106-vision-preview',
                    'moonshot-v1-8k',
                    'moonshot-v1-32k',
                    'moonshot-v1-128k'
                ],
                value=Configs['Chatgpt']['gpt_model'], interactive=True,
                label="é€‰æ‹©chatgptæ¨¡å‹", 
                elem_id="chatpgtSwitch"
            )
            prompt = gr.Textbox(                
                min_width=80, 
                elem_id="prompt"
                )

            upfile= gr.Files(label="ä¸Šä¼ æ–‡ä»¶,æ”¯æŒpdf docx txtç­‰æ ¼å¼", min_width=80, elem_id="upfile")
        with gr.Column(scale=5, elem_id="chatPanel"):
            bot_component = gr.Chatbot(
                min_width=100,
                label='èŠå¤©æ¡†', 
                avatar_images=utils.getAvatars(), 
                elem_id="chatbot",
                show_label=False,
                show_share_button=False,
                sanitize_html=False,
            )
            with gr.Row(elem_id="inputPanel"):
                text_input = gr.Textbox(placeholder="ç‚¹å‡»è¾“å…¥", show_label=False, scale=4, elem_id="textInput")
                submit_button = gr.Button(value="å‘é€", size="sm", min_width=80, elem_id="submitButton")
                clear_button = gr.Button(value="æ¸…é™¤", size="sm", min_width=80, elem_id="cleanButton")
        
        def read_data(files):
            docs = []
            for file in files:
                print(f"Loading file: {file}")
                ext_name = os.path.splitext(file)[-1]
                # print(ext_name)

                if ext_name == ".pptx":
                    loader = UnstructuredPowerPointLoader(file)
                elif ext_name == ".docx":
                    loader = UnstructuredWordDocumentLoader(file)
                elif ext_name == ".pdf":
                    loader = PyPDFLoader(file)
                elif ext_name == ".csv":
                    loader = CSVLoader(file_path=file)
                elif ext_name == ".xml":
                    loader = MWDumpLoader(file_path=file, encoding="utf8")
                else:
                    # process .txt, .html
                    loader = UnstructuredFileLoader(file)

                doc = loader.load_and_split(text_splitter)            
                docs.extend(doc)
            return doc



        def autoChat(files: list, prompt: str, message: str, chat_history: list) -> tuple[str, list[list[str, str]]]:
            """
            è‡ªåŠ¨æ ¹æ®å½“å‰å‰ç«¯ä¿¡æ¯ï¼Œé€‰æ‹©èŠå¤©æ–¹å¼è¿›è¡ŒèŠå¤©


            :param message: str ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
            :param chat_history: [[str, str]...] åˆ†åˆ«ä¸ºç”¨æˆ·è¾“å…¥å’Œæœºå™¨äººå›å¤(å…ˆå‰çš„)
            :return: tuple[str, list[list[str, str]]] ç©ºå­—ç¬¦ä¸²(ç”¨ä»¥æ¸…ç©ºè¾“å…¥æ¡†), æ›´æ–°çš„æ¶ˆæ¯è®°å½•
            """
            if not message:
                return "", chat_history,[]
            if files:
                files_data = str(read_data(files))
            else:
                files_data = ''
            if not prompt:
                prompt = ''
            try:
                bot_message = chatgpt_service.continuedQuery(files_data, prompt, message, chat_history)
            
            except RateLimitError as e:
                gr.Warning(e.body['message'])
            except APIConnectionError as e:
                gr.Warning('Apiè¿æ¥é”™è¯¯')
            except Exception as e:
                gr.Warning(e)
            return "", chat_history, files
        
        def switchchatgpt(select_service_name: str):
            """
            åˆ‡æ¢chatgptæ¨¡å‹
            :param select_service_name: str chatgptæ¨¡å‹åç§°
            :return: str chatgptæ¨¡å‹åç§°
            """
            global chatgpt_service, chatgpt_switch
            current_service_name = chatgpt_service.model  # å½“å‰çš„chatgptæ¨¡å‹åç§°
            if select_service_name == current_service_name:
                return current_service_name
            else:  # å°è¯•åˆ‡æ¢æ¨¡å‹
                try:
                    if select_service_name in [
                        'gpt-3.5-turbo',
                        'gpt-3.5-turbo-16k',
                        'gpt-4',
                        'gpt-4-0125-preview',
                        'gpt-4-turbo-preview',
                        'gpt-4-1106-preview',
                        'gpt-4-vision-preview',
                        'gpt-4-1106-vision-preview',
                        'moonshot-v1-8k',
                        'moonshot-v1-32k',
                        'moonshot-v1-128k'
                    ]: 
                        Configs["Chatgpt"]['gpt_model'] = select_service_name
                        temp_service = ChatGPT(utils.Configs["Chatgpt"])

                    else:  # æœªçŸ¥çš„æ¨¡å‹é€‰æ‹©ï¼Œä¸æ‰§è¡Œåˆ‡æ¢
                        gr.Warning(f"æœªçŸ¥çš„chatgptæ¨¡å‹ï¼Œå°†ä¸è¿›è¡Œåˆ‡æ¢ï¼Œå½“å‰ï¼š{current_service_name}")
                        return current_service_name
                    chatgpt_service = temp_service
                    gr.Info(f"æ¨¡å‹åˆ‡æ¢æˆåŠŸï¼Œå½“å‰ï¼š{chatgpt_service.model}")
                    return chatgpt_service.model
                except Exception:
                    traceback.print_exc()
                    gr.Warning("æ¨¡å‹åˆ‡æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ¨¡å‹é…ç½®")
                    return current_service_name

        def load_chat_history(*args):
            return chatgpt_service.load_chat_history(*args)
        load_history_from_file_args = dict(
            fn=load_chat_history,
            inputs=[historySelectList],
            outputs=[bot_component],
        )

        # èŠå¤©å†å²æ•°æ®åŠ è½½
        historySelectList.input(**load_history_from_file_args)


        # æŒ‰é’®ç»‘å®šäº‹ä»¶
        clear_button.click(
            fn=lambda message, chat_history, file: ("", [], []),
            inputs=[text_input, bot_component, upfile],
            outputs=[text_input, bot_component, upfile]
        )

        submit_button.click(autoChat, [upfile,prompt,text_input, bot_component], [text_input, bot_component, upfile])
        text_input.submit(autoChat, [upfile,prompt,text_input, bot_component], [text_input, bot_component, upfile])

        # åˆ‡æ¢æ¨¡å‹
        chatgpt_switch.change(switchchatgpt, [chatgpt_switch], [chatgpt_switch,])
 
app = gr.mount_gradio_app(app, chat_demo, path="/chatbot")
if __name__ == "__main__":
    uvicorn.run(app)